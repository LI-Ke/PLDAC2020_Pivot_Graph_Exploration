{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import for spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from graphviz import *\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import needed for interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction\n",
    "# from __future__ import print_function\n",
    "# from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "# import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start spark engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark application id is: local-1580404823067\n"
     ]
    }
   ],
   "source": [
    "#spark.stop()\n",
    "\n",
    "local = \"local[*]\"\n",
    "appName = \"Essai graph spark\"\n",
    "memory=\"8G\"\n",
    "\n",
    "configLocale = SparkConf().setAppName(appName).setMaster(local).\\\n",
    "set(\"spark.executor.memory\", memory).\\\n",
    "set(\"spark.driver.memory\", memory).\\\n",
    "set(\"spark.sql.catalogImplementation\",\"in-memory\")\n",
    "spark = SparkSession.builder.config(conf = configLocale).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"Spark application id is:\", sc.applicationId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA-DIR:data/wiley/\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"data\"\n",
    "DATA_DIR = DATA_ROOT + \"/wiley/\"\n",
    "#DATA_DIR = DATA_ROOT + \"/glyphosate/\"\n",
    "#DATA_DIR = DATA_ROOT + \"/istex/\"\n",
    "\n",
    "print('DATA-DIR:' + DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------------------+\n",
      "|idTopic1|idTopic2|similarity        |\n",
      "+--------+--------+------------------+\n",
      "|110     |129     |0.2637034579858007|\n",
      "+--------+--------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarityLinks = spark.read.json(DATA_DIR + 'similarityLinks')\n",
    "similarityLinks.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+---------+------+-------------------+\n",
      "|idTopic|localTopicId|period   |term  |weight             |\n",
      "+-------+------------+---------+------+-------------------+\n",
      "|0      |0           |1996-1998|229917|0.0315334897631547 |\n",
      "|0      |0           |1996-1998|284153|0.05503559027472268|\n",
      "|0      |0           |1996-1998|248801|0.02087863877952271|\n",
      "+-------+------------+---------+------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topicNodes = spark.read.json(DATA_DIR + 'topicNodes')\n",
    "# topicNodes.show(1, False)\n",
    "topicNodes.orderBy(\"idTopic\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+---------+------+--------------------+\n",
      "|idTopic|localTopicId|period   |term  |weight              |\n",
      "+-------+------------+---------+------+--------------------+\n",
      "|110    |10          |2006-2008|150733|0.021343152963741938|\n",
      "|110    |10          |2006-2008|82283 |0.02032438978321691 |\n",
      "|110    |10          |2006-2008|98297 |0.02008320493272858 |\n",
      "|110    |10          |2006-2008|248801|0.018483870163718896|\n",
      "|110    |10          |2006-2008|234634|0.018380649583723516|\n",
      "+-------+------------+---------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topicNodes.where(\"idTopic = 110\").show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term dictionary (terms to display in the global graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------+\n",
      "|id   |term                 |\n",
      "+-----+---------------------+\n",
      "|156  |101002 cae 101002 cae|\n",
      "|5745 |ABC concept          |\n",
      "|6806 |Abstract study       |\n",
      "|7809 |Anycast services     |\n",
      "|10821|CR networks          |\n",
      "+-----+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocabularies = spark.read.json(DATA_DIR + 'wiley_CS_voc_199620153220')\n",
    "vocabularies.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|    id|  term|\n",
      "+------+------+\n",
      "|150733|impact|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocabularies.where(\"id = 150733\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### topicDictionary_unique_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------------------------------------------------------------+\n",
      "|idTopic|topic                                                                                              |\n",
      "+-------+---------------------------------------------------------------------------------------------------+\n",
      "|34     |[solve, solution, problems, compute, case, approximation, analysis, literature, step, terms]       |\n",
      "|52     |[case, interaction, capable, calculate, terms, validate, experiments, predict, methodology, motion]|\n",
      "+-------+---------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topicDictionary_unique_10 = spark.read.json(DATA_DIR + 'topicDictionary_unique_10')\n",
    "topicDictionary_unique_10.show(2, False)\n",
    "# topicDictionary_unique_10.groupBy().max(\"idTopic\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------------------------------------+\n",
      "|idTopic|topic                                                                                 |\n",
      "+-------+--------------------------------------------------------------------------------------+\n",
      "|110    |[impact, complexity, deployment, run, quality, tool, attacks, due, internet, response]|\n",
      "+-------+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topicDictionary_unique_10.where(\"idTopic = 110\").show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evolutionPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.5\n",
    "\n",
    "nbTopicPerPeriod = 20\n",
    "\n",
    "pivotDir = str(beta)+\"_\" + str(nbTopicPerPeriod) + \"_0.0_10/\"\n",
    "\n",
    "future = spark.read.json(DATA_DIR + '/evolutionPath/' + pivotDir + \"future\")\n",
    "past = spark.read.json(DATA_DIR + '/evolutionPath/' + pivotDir + \"past\")\n",
    "labels = spark.read.json(DATA_DIR + '/evolutionPath/' + pivotDir + \"labels\")\n",
    "\n",
    "# future.show(1, False)\n",
    "# past.show(1, False)\n",
    "# labels.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Alpha: double (nullable = true)\n",
      " |-- Beta: double (nullable = true)\n",
      " |-- Pi: long (nullable = true)\n",
      " |-- Pj: long (nullable = true)\n",
      " |-- Pk: long (nullable = true)\n",
      " |-- Ti: long (nullable = true)\n",
      " |-- Tj: long (nullable = true)\n",
      " |-- Tk: long (nullable = true)\n",
      " |-- TopicI: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- TopicJ: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- TopicK: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- localRank: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "future.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#labels.printSchema()\n",
    "labels.createOrReplaceTempView(\"labels\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_future = spark.read.json(DATA_DIR + 'statistics_future')\n",
    "stats = spark.read.json(DATA_DIR + 'statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+-----+----------+--------------------+-----------------+-----------------------+-----------+-------+-----+----------------------------+-------------------------------------------------------------------------------------------+-----------+\n",
      "|Beta|ConvergenceDegree|Depth|Liveliness|PivotEvolutionDegree|PublicationPeriod|RelativeEvolutionDegree|SplitDegree|TopicID|dying|emerging                    |genetic                                                                                    |special    |\n",
      "+----+-----------------+-----+----------+--------------------+-----------------+-----------------------+-----------+-------+-----+----------------------------+-------------------------------------------------------------------------------------------+-----------+\n",
      "|0.1 |7.25             |8    |1.0       |0.844               |1998-2000        |0.779                  |8.352      |20     |[]   |[goal]                      |[implementation, knowledge, structure, technology, process, techniques, integration, basis]|[formalism]|\n",
      "|0.1 |7.211            |7    |1.0       |0.895               |2000-2002        |0.775                  |8.474      |45     |[]   |[]                          |[flows, equations, solution, stokes, solve, time, navier, comparison, scheme, velocity]    |[]         |\n",
      "|0.1 |7.24             |7    |1.0       |0.869               |2000-2002        |0.776                  |8.588      |47     |[]   |[view, students, cae, guide]|[users, learning, concept, task, means, objects]                                           |[]         |\n",
      "+----+-----------------+-----+----------+--------------------+-----------------+-----------------------+-----------+-------+-----+----------------------------+-------------------------------------------------------------------------------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_future.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------+-----------+----------------+--------------------------+-----------------------------+-----------------+---------------------+---------+--------------+------------------------+---------------------------+---------------+-----------------+-------+-----+--------+-------------------------------------------------------------------------------------------+-----------+\n",
      "|Beta|FutureConvergenceDegree|FutureDepth|FutureLiveliness|FuturePivotEvolutionDegree|FutureRelativeEvolutionDegree|FutureSplitDegree|PastConvergenceDegree|PastDepth|PastLiveliness|PastPivotEvolutionDegree|PastRelativeEvolutionDegree|PastSplitDegree|PublicationPeriod|TopicID|dying|emerging|genetic                                                                                    |special    |\n",
      "+----+-----------------------+-----------+----------------+--------------------------+-----------------------------+-----------------+---------------------+---------+--------------+------------------------+---------------------------+---------------+-----------------+-------+-----+--------+-------------------------------------------------------------------------------------------+-----------+\n",
      "|0.1 |7.25                   |8          |1.0             |0.844                     |0.779                        |8.352            |11.0                 |1        |1.0           |0.811                   |0.811                      |1.0            |1998-2000        |20     |[]   |[goal]  |[implementation, knowledge, structure, technology, process, techniques, integration, basis]|[formalism]|\n",
      "+----+-----------------------+-----------+----------------+--------------------------+-----------------------------+-----------------+---------------------+---------+--------------+------------------------+---------------------------+---------------+-----------------+-------+-----+--------+-------------------------------------------------------------------------------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.show(1,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
